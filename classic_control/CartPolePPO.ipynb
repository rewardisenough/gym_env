{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fabbe1-4323-4f23-a34b-2279f5d3829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 17:41:32,168\tINFO worker.py:1528 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.13', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-12_17-41-30_579813_2066/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-12_17-41-30_579813_2066/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-11-12_17-41-30_579813_2066', 'metrics_export_port': 65180, 'gcs_address': '127.0.0.1:64093', 'address': '127.0.0.1:64093', 'dashboard_agent_listen_port': 52365, 'node_id': '3dace6c73e610e7a87c3dd7774c3ca2642492e7acbdca0eaa7ed925d'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce010a1f-76a7-4d98-a03a-edc41ea10c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib import train\n",
    "\n",
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a64a1ce-02ce-4096-9cb1-18f9efd0737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-12 17:43:43</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:08.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.1/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/5.88 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  num_recreated_worker\n",
       "s</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_aed06_00000</td><td>RUNNING </td><td>127.0.0.1:2099</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         48.9915</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">   42.65</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">                 220</td><td style=\"text-align: right;\">                  10</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1112 17:42:34.981449000 8116724992 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m 2022-11-12 17:42:39,114\tINFO algorithm.py:2303 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m 2022-11-12 17:42:39,114\tINFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m 2022-11-12 17:42:39,115\tINFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2108)\u001b[0m Metal device set to: Apple M1 Pro\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2107)\u001b[0m Metal device set to: Apple M1 Pro\n",
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m 2022-11-12 17:42:44,148\tWARNING deprecation.py:47 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=2099)\u001b[0m 2022-11-12 17:42:44,478\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                        </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>evaluation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </th><th>experiment_id                   </th><th>hostname                </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_recreated_workers</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                            </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                     </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                                   </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_aed06_00000</td><td style=\"text-align: right;\">                   8000</td><td>{&#x27;num_env_steps_sampled&#x27;: 8000, &#x27;num_env_steps_trained&#x27;: 8000, &#x27;num_agent_steps_sampled&#x27;: 8000, &#x27;num_agent_steps_trained&#x27;: 8000}</td><td>{}              </td><td>2022-11-12_17-43-33</td><td>False </td><td style=\"text-align: right;\">             42.65</td><td>{}             </td><td style=\"text-align: right;\">                 220</td><td style=\"text-align: right;\">                42.65</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">                  83</td><td style=\"text-align: right;\">             278</td><td>{&#x27;episode_reward_max&#x27;: 223.0, &#x27;episode_reward_min&#x27;: 18.0, &#x27;episode_reward_mean&#x27;: 114.75, &#x27;episode_len_mean&#x27;: 114.75, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 20, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [137.0, 66.0, 125.0, 43.0, 167.0, 84.0, 186.0, 86.0, 118.0, 84.0, 168.0, 223.0, 18.0, 111.0, 155.0, 22.0, 160.0, 77.0, 61.0, 204.0], &#x27;episode_lengths&#x27;: [137, 66, 125, 43, 167, 84, 186, 86, 118, 84, 168, 223, 18, 111, 155, 22, 160, 77, 61, 204]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.14086083252670875, &#x27;mean_inference_ms&#x27;: 4.193234111373849, &#x27;mean_action_processing_ms&#x27;: 0.0480276366974834, &#x27;mean_env_wait_ms&#x27;: 0.0364059770564169, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;num_agent_steps_sampled_this_iter&#x27;: 2295, &#x27;num_env_steps_sampled_this_iter&#x27;: 2295, &#x27;timesteps_this_iter&#x27;: 2295, &#x27;num_recreated_workers&#x27;: 0, &#x27;num_healthy_workers&#x27;: 0}</td><td>6d5a09d9025440fd992a0c55a382d782</td><td>Davids-MacBook-Pro.local</td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;cur_kl_coeff&#x27;: 0.30000001192092896, &#x27;cur_lr&#x27;: 4.999999873689376e-05, &#x27;total_loss&#x27;: 9.268851, &#x27;policy_loss&#x27;: -0.031329956, &#x27;vf_loss&#x27;: 9.295016, &#x27;vf_explained_var&#x27;: -0.0517344, &#x27;kl&#x27;: 0.01721756, &#x27;entropy&#x27;: 0.61934996, &#x27;entropy_coeff&#x27;: 0.0, &#x27;model&#x27;: {}}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 128.0}}, &#x27;num_env_steps_sampled&#x27;: 8000, &#x27;num_env_steps_trained&#x27;: 8000, &#x27;num_agent_steps_sampled&#x27;: 8000, &#x27;num_agent_steps_trained&#x27;: 8000}</td><td style=\"text-align: right;\">                         2</td><td>127.0.0.1</td><td style=\"text-align: right;\">                     8000</td><td style=\"text-align: right;\">                     8000</td><td style=\"text-align: right;\">                   8000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                   8000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: 44.147619047619045, &#x27;ram_util_percent&#x27;: 56.688095238095244}</td><td style=\"text-align: right;\"> 2099</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 0.1831963026812162, &#x27;mean_inference_ms&#x27;: 4.387022320926256, &#x27;mean_action_processing_ms&#x27;: 0.052971536754378726, &#x27;mean_env_wait_ms&#x27;: 0.04124616562266075, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 220.0, &#x27;episode_reward_min&#x27;: 10.0, &#x27;episode_reward_mean&#x27;: 42.65, &#x27;episode_len_mean&#x27;: 42.65, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 83, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [14.0, 15.0, 24.0, 37.0, 14.0, 18.0, 20.0, 32.0, 26.0, 11.0, 18.0, 11.0, 19.0, 21.0, 19.0, 33.0, 13.0, 39.0, 27.0, 49.0, 27.0, 56.0, 37.0, 42.0, 78.0, 13.0, 23.0, 13.0, 51.0, 34.0, 61.0, 55.0, 77.0, 49.0, 90.0, 78.0, 11.0, 24.0, 37.0, 80.0, 31.0, 31.0, 81.0, 15.0, 10.0, 79.0, 19.0, 61.0, 48.0, 102.0, 14.0, 73.0, 12.0, 53.0, 52.0, 20.0, 56.0, 70.0, 79.0, 12.0, 29.0, 86.0, 67.0, 45.0, 19.0, 30.0, 22.0, 11.0, 63.0, 16.0, 33.0, 29.0, 183.0, 32.0, 10.0, 81.0, 19.0, 21.0, 61.0, 41.0, 11.0, 69.0, 44.0, 26.0, 24.0, 25.0, 220.0, 10.0, 28.0, 51.0, 31.0, 112.0, 44.0, 74.0, 33.0, 101.0, 41.0, 29.0, 31.0, 49.0], &#x27;episode_lengths&#x27;: [14, 15, 24, 37, 14, 18, 20, 32, 26, 11, 18, 11, 19, 21, 19, 33, 13, 39, 27, 49, 27, 56, 37, 42, 78, 13, 23, 13, 51, 34, 61, 55, 77, 49, 90, 78, 11, 24, 37, 80, 31, 31, 81, 15, 10, 79, 19, 61, 48, 102, 14, 73, 12, 53, 52, 20, 56, 70, 79, 12, 29, 86, 67, 45, 19, 30, 22, 11, 63, 16, 33, 29, 183, 32, 10, 81, 19, 21, 61, 41, 11, 69, 44, 26, 24, 25, 220, 10, 28, 51, 31, 112, 44, 74, 33, 101, 41, 29, 31, 49]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 0.1831963026812162, &#x27;mean_inference_ms&#x27;: 4.387022320926256, &#x27;mean_action_processing_ms&#x27;: 0.052971536754378726, &#x27;mean_env_wait_ms&#x27;: 0.04124616562266075, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             48.9915</td><td style=\"text-align: right;\">           29.5891</td><td style=\"text-align: right;\">       48.9915</td><td>{&#x27;training_iteration_time_ms&#x27;: 19409.184, &#x27;load_time_ms&#x27;: 0.11, &#x27;load_throughput&#x27;: 36353664.139, &#x27;learn_time_ms&#x27;: 10047.619, &#x27;learn_throughput&#x27;: 398.104, &#x27;synch_weights_time_ms&#x27;: 2.184}</td><td style=\"text-align: right;\"> 1668296613</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">             8000</td><td style=\"text-align: right;\">                   2</td><td>aed06_00000</td><td style=\"text-align: right;\">      5.36655</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 17:43:42,578\tWARNING tune.py:705 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2022-11-12 17:43:43,800\tERROR tune.py:773 -- Trials did not complete: [PPO_CartPole-v1_aed06_00000]\n",
      "2022-11-12 17:43:43,801\tINFO tune.py:777 -- Total run time: 72.67 seconds (68.74 seconds for the tuning loop).\n",
      "2022-11-12 17:43:43,801\tWARNING tune.py:783 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x17b216b20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "tune.run(\"PPO\",\n",
    "         config={\"env\": \"CartPole-v1\",\n",
    "                 \"evaluation_interval\": 2,\n",
    "                 \"evaluation_duration\": 20\n",
    "                 },\n",
    "         local_dir=\"cartpole_v1\",\n",
    "         checkpoint_freq=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5612614a-5ab8-4b4e-8f84-d5eff85a7f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2313)\u001b[0m Metal device set to: Apple M1 Pro\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2314)\u001b[0m Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 18:01:30,855\tWARNING deprecation.py:47 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-11-12 18:01:31,186\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not recover from checkpoint as it does not exist on local disk and was not available on cloud storage or another Ray node. Got checkpoint path: gym_env/classic_control/cartpole_v1/PPO/PPO_CartPole-v1_aed06_00000_0_2022-11-12_17-42-34/checkpoint_000002/policies/default_policy/rllib_checkpoint.json and IP None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPOTrainer\n\u001b[1;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m PPOTrainer(config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCartPole-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_duration\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      6\u001b[0m                  })\n\u001b[0;32m----> 7\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgym_env/classic_control/cartpole_v1/PPO/PPO_CartPole-v1_aed06_00000_0_2022-11-12_17-42-34/checkpoint_000002/policies/default_policy/rllib_checkpoint.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:729\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip, fallback_to_latest)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore(checkpoint_path, fallback_to_latest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# Else, raise\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not recover from checkpoint as it does not exist on local \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk and was not available on cloud storage or another Ray node. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and IP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_node_ip\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m     )\n\u001b[1;32m    735\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m TrainableUtil\u001b[38;5;241m.\u001b[39mfind_checkpoint_dir(checkpoint_path)\n\u001b[1;32m    736\u001b[0m metadata \u001b[38;5;241m=\u001b[39m TrainableUtil\u001b[38;5;241m.\u001b[39mload_metadata(checkpoint_dir)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not recover from checkpoint as it does not exist on local disk and was not available on cloud storage or another Ray node. Got checkpoint path: gym_env/classic_control/cartpole_v1/PPO/PPO_CartPole-v1_aed06_00000_0_2022-11-12_17-42-34/checkpoint_000002/policies/default_policy/rllib_checkpoint.json and IP None"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "\n",
    "agent = PPOTrainer(config={\"env\": \"CartPole-v1\",\n",
    "                 \"evaluation_interval\": 2,\n",
    "                 \"evaluation_duration\": 20\n",
    "                 })\n",
    "agent.restore(\"gym_env/classic_control/cartpole_v1/PPO/PPO_CartPole-v1_aed06_00000_0_2022-11-12_17-42-34/checkpoint_000002/policies/default_policy/rllib_checkpoint.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84faab-e238-4849-bf88-1d40d4bfcbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
